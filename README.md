ğŸŒ± CodeRoot AI â€” Local Code Explanation Engine
Powered by Ollama + CodeLlama

CodeRoot AI is a privacy-focused, offline code explanation engine that uses CodeLlama through Ollama to interpret and explain code instantly. It ensures that your code stays on your machine, offering fast, secure, and intelligent analysis without depending on cloud services.

ğŸ§© Project Description

CodeRoot AI is designed to help developers understand unfamiliar or complex code by generating clear, human-readable explanations directly from their local machine. With its modular architecture and simple command-line interface, it delivers fast, private, and offline code intelligence using open-source LLM models.
Built for students, developers, and researchers, CodeRoot AI combines portability, performance, and complete code privacy.

ğŸš€ Features

ğŸ§  AI-powered code understanding using CodeLlama

ğŸ”’ Fully offline â€” code never leaves your machine

âš¡ Fast and lightweight

ğŸ–¥ï¸ CLI-based simple interface

ğŸ“¦ Modular and extensible architecture

ğŸ§© Works on Windows, macOS, and Linux

ğŸ› ï¸ Requirements
1. Python 3.10+

Check if Python is installed:

python --version

2. Install Ollama

Download and install Ollama from:
ğŸ”— https://ollama.com/download

Verify the installation:

ollama --version

3. Download CodeLlama Model

Before running CodeRoot AI:

ollama pull codellama

ğŸ“¥ Installation

Clone the repository:

git clone https://github.com/Sudhi3276/code-explainer.git
cd code-explainer


Create a virtual environment:

python -m venv venv


Activate it:

.\venv\Scripts\activate       # Windows
source venv/bin/activate      # macOS/Linux


Install dependencies:

pip install -r requirements.txt

â–¶ï¸ How to Run CodeRoot AI

Start the program:

python main.py


You will be prompted to paste your code snippet, and CodeRoot AI will generate a detailed explanation using CodeLlama.
